#include <iostream>
#include <string>
#include <vector>
#include <regex>
#include <thread>
#include <mutex>
#include <unordered_set>
#include <curl/curl.h>

std::unordered_set<std::string> visitedURLs;
std::mutex urlMutex;

size_t WriteCallback(void* contents, size_t size, size_t nmemb, std::string* output) {
    size_t totalSize = size * nmemb;
    output->append((char*)contents, totalSize);
    return totalSize;
}

std::string fetchHTML(const std::string& url) {
    CURL* curl;
    CURLcode res;
    std::string response;

    curl = curl_easy_init();
    if (curl) {
        curl_easy_setopt(curl, CURLOPT_URL, url.c_str());
        curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
        curl_easy_setopt(curl, CURLOPT_WRITEDATA, &response);
        res = curl_easy_perform(curl);
        curl_easy_cleanup(curl);
    }
    return response;
}

std::vector<std::string> extractLinks(const std::string& html) {
    std::vector<std::string> links;
    std::regex linkPattern(R"(<a\s+href=["'](https?://[^"']+)["'])");
    std::smatch match;
    std::string::const_iterator searchStart(html.cbegin());

    while (std::regex_search(searchStart, html.cend(), match, linkPattern)) {
        links.push_back(match[1]);
        searchStart = match.suffix().first;
    }
    return links;
}

void crawlURL(const std::string& url) {
    std::lock_guard<std::mutex> guard(urlMutex);
    if (visitedURLs.find(url) != visitedURLs.end()) return;
    visitedURLs.insert(url);

    std::string html = fetchHTML(url);
    std::vector<std::string> links = extractLinks(html);
    
    std::cout << "Crawled: " << url << " | Found " << links.size() << " links\n";
}

void multiThreadedCrawl(const std::vector<std::string>& urls) {
    std::vector<std::thread> threads;
    for (const auto& url : urls) {
        threads.emplace_back(crawlURL, url);
    }
    for (auto& thread : threads) {
        thread.join();
    }
}

int main() {
    std::vector<std::string> startURLs = {"https://www.youtube.com/", "https://www.geeksforgeeks.org/"};
    multiThreadedCrawl(startURLs);
    return 0;
}